---
title: "Overview of Neural Networks"
author: "Dominik Klepl"
date: "10/12/2019"
output: html_document
---

Artificial neural networks (ANN) are another class of machine learning models. Unlike methods covered in the ML course that were mostly inspired by statistical inference, ANNs are inspired by the structure of biological brains.
Or if you want a more fun explanation of the difference between stats and neural networks, here's the perfect meme. 
**Neural networks are simply more experince in the data yoga but this comes at a price. Computational price!!!**
![Data yoga](img/yoga.png "Data yoga")

In this guide, I'll cover all types of ANNs that were introduced in the course + some bonus ones.

**!!!NOTE!!!** Since I'm obsessed with brains, I'll use the brain inspiration a lot to explain how each type of ANN works. So apologies in advance.

### Contents
- Perceptron
- Multilayer perceptron
- Backpropagation
- Self-organizing maps (Kohonen network)
- Hopfield networks
- Bidirectional associative memory (BAM)
- Radial basis funcion (RBF)
- Recurrent neural networks (RNN)
- Long short-term memory (LSTM)
- Convolusional networks (CNN)
- (Deep) Autoencoder
- Deep reinforcement learning
- BONUS 1: Attention neural networks
- BONUS 2: Generative adversial network

# Perceptron

# Multilayer perceptron

# Backpropagation

# Self-organizing maps

# Hopfield networks

# Bidirectional associative memory 

# Radial basis funcion

# Recurrent neural networks

# Long short-term memory

# Convolusional networks

# (Deep) Autoencoder

# Deep reinforcement learning

# BONUS 1: Attention neural networks

# BONUS 2: Generative adversial network